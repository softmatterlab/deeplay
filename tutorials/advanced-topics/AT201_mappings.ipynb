{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Mappings as Inputs\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/DeepTrackAI/deeplay/blob/develop/tutorials/advanced-topics/AT201_mappings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeplay  # Uncomment if running on Colab/Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DeeplayModule` objects can take mappings—such as Python dictionaries—as inputs, making it easy to define and manage complex data processing pipelines. By using mappings, you can organize and access data flexibly, allowing models to handle a wide range of inputs seamlessly. This is especially useful when working with multiple input types, customizing sequential data processing, or setting up parallel pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Mappings in Deeplay\n",
    "\n",
    "When using mappings as inputs to `DeeplayModule` objects, you define the relationship between your input and output data structures by configuring the `.set_input_map()` and `.set_output_map()` methods of the module. For instance, you can clearly indicate which input features feed into specific layers or operations, ensuring that your model processes data correctly and efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, this code defines a linear module that takes a dictionary with the key `x` as input and produces an output stored under a different key, `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer[Linear](in_features=10, out_features=64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deeplay as dl\n",
    "import torch\n",
    "\n",
    "module = dl.Layer(torch.nn.Linear, 10, 64)\n",
    "\n",
    "module.set_input_map(\"x\")\n",
    "module.set_output_map(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set the output key to be the same as the input key, we can define a linear module that takes a dictionary with the key `x` as input and overwrites the value associated with `x` with the output of the linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer[Linear](in_features=10, out_features=64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = dl.Layer(torch.nn.Linear, 10, 64)\n",
    "\n",
    "module.set_input_map(\"x\")\n",
    "module.set_output_map(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the module is built, the input data can be passed to the module as with `Tensor` objects. The module will automatically map the input and output data to the expected data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output keys:  dict_keys(['x'])\n",
      "input x shape:  torch.Size([20, 10])\n",
      "output x shape:  torch.Size([20, 64])\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    'x': torch.randn(20, 10),\n",
    "}\n",
    "\n",
    "built = module.build()\n",
    "\n",
    "output_data = built(input_data)\n",
    "\n",
    "print(\"output keys: \", output_data.keys())\n",
    "print(\"input x shape: \", input_data['x'].shape)\n",
    "print(\"output x shape: \", output_data['x'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently supported mapping objects include dictionaries, such as ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    'x': torch.randn(20, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and Torch Geometric Data objects, like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "input_data = Data(\n",
    "    x=torch.randn(3, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations with Mappings\n",
    "\n",
    "The `.set_input_map()` method allows for local key re-assignment. This is particularly useful when the keys in the input data do not align with the keys expected by the module. By using this method, you can explicitly define how your input data should be mapped to the keys that the module will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we create a multi-head attention module, which expects inputs in the form of query, key, and value tensors. Here, we use the same input, `x`, for all three inputs—query, key, and value.This demonstrates how to configure the mappings to align with the module's requirements, even if the input data is organized differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer[MultiheadAttention](embed_dim=10, num_heads=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = dl.Layer(torch.nn.MultiheadAttention, embed_dim=10, num_heads=2)\n",
    "\n",
    "module.set_input_map(query=\"x\", key=\"x\", value=\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can configure the output mapping of the multi-head attention module. Using the `.set_output_map()` method, we define the ouput mappings, where the attention output is mapped to `x` and the attention weights are mapped to `attention_weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer[MultiheadAttention](embed_dim=10, num_heads=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.set_output_map(\"x\", \"attention_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can specify the output mappings using their indices. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer[MultiheadAttention](embed_dim=10, num_heads=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.set_output_map(x=0, attention_weights=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `x=0` and `attention_weights=1` indicate that the output dictionary will assosiate the first output of the module with `x` and the second output with `attention_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output keys:  ['x', 'attention_weights']\n",
      "output x shape:  torch.Size([100, 10])\n",
      "output attention_weights shape:  torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "built = module.build()\n",
    "\n",
    "input_data = Data(x=torch.randn(100, 10))\n",
    "\n",
    "output_data = built(input_data)\n",
    "\n",
    "print(\"output keys: \", output_data.keys())\n",
    "print(\"output x shape: \", input_data.x.shape)\n",
    "print(\"output attention_weights shape: \", output_data.attention_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add new keys to the output data structure to store intermediate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer[MultiheadAttention](embed_dim=10, num_heads=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = dl.Layer(torch.nn.MultiheadAttention, embed_dim=10, num_heads=2)\n",
    "\n",
    "module.set_input_map(query=\"x\", key=\"x\", value=\"x\")\n",
    "\n",
    "module.set_output_map(\n",
    "    x=0,\n",
    "    intermediate_x=0,\n",
    "    attention_weights=1,\n",
    "    intermediate_attention_weights=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first output of the module is mapped to both `x` and `intermediate_x`, allowing you to store the same result in two different keys. Similarly, the second output is mapped to both `attention_weights` and `intermediate_attention_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output keys:  ['x', 'attention_weights', 'intermediate_x', 'intermediate_attention_weights']\n",
      "output x shape:  torch.Size([100, 10])\n",
      "output intermediate_x shape:  torch.Size([100, 10])\n",
      "output attention_weights shape:  torch.Size([100, 100])\n",
      "output intermediate_attention_weights shape:  torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "built = module.build()\n",
    "\n",
    "input_data = Data(x=torch.randn(100, 10))\n",
    "\n",
    "output_data = built(input_data)\n",
    "\n",
    "print(\"output keys: \", output_data.keys())\n",
    "\n",
    "print(\"output x shape: \", input_data.x.shape)\n",
    "print(\"output intermediate_x shape: \", output_data.intermediate_x.shape)\n",
    "\n",
    "print(\"output attention_weights shape: \", output_data.attention_weights.shape)\n",
    "print(\n",
    "    \"output intermediate_attention_weights shape: \",\n",
    "    output_data.intermediate_attention_weights.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings Allow Sequential Processing\n",
    "\n",
    "Mappings enable the sequencing of branched pipelines, giving you full control over how data flows through each module. This allows you to fully exploit the modular design of `DeeplayModule` objects. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import LayerNorm\n",
    "\n",
    "module = dl.Sequential(\n",
    "    dl.Layer(torch.nn.Bilinear, 10, 10, 10) \\\n",
    "        .set_input_map(\"x1\", \"x2\").set_output_map(\"y\"),\n",
    "    dl.Layer(LayerNorm, 10) \\\n",
    "        .set_input_map(x=\"y\", batch=\"batch\").set_output_map(\"y\"),\n",
    "    dl.Add().set_input_map(\"x1\", \"y\").set_output_map(\"x1\"),\n",
    "    dl.Add().set_input_map(\"x2\", \"y\").set_output_map(\"x2\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above:\n",
    "\n",
    "1. The first layer combines inputs `x1` and `x2` unsig a bilinear operation, producing an output labeled `y`. \n",
    "\n",
    "2. Next, a layer normalization is applied to `y`, using batch information from the `batch` input. The result is again assigned to `y`. \n",
    "\n",
    "3. Finally, `x1` and `x2` are independently summed with `y`. Each of these sums is stored back into their respective keys `x1` and `x2`, thereby implementing a residual connection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output keys:  ['y', 'x2', 'batch', 'x1']\n",
      "output x1 shape:  torch.Size([5, 10])\n",
      "output x2 shape:  torch.Size([5, 10])\n",
      "output y shape:  torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "built = module.build()\n",
    "\n",
    "input_data = Data(\n",
    "    x1=torch.randn(5, 10),\n",
    "    x2=torch.randn(5, 10),\n",
    "    batch=torch.Tensor([0, 0, 0, 1, 1]).long(),\n",
    ")\n",
    "\n",
    "output_data = built(input_data)\n",
    "\n",
    "print(\"output keys: \", output_data.keys())\n",
    "print(\"output x1 shape: \", output_data.x1.shape)\n",
    "print(\"output x2 shape: \", output_data.x2.shape)\n",
    "print(\"output y shape: \", output_data.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Parallel Pipelines\n",
    "\n",
    "With Deeplay's `Parallel` objects, you can create piplines that process input mapping objects concurrently. Each module in the your pipeline will receive the input data, extract the relevant keys, and handle the processing independently. Finally, the outputs from each module are stored as separate keys within a single mapping object, allowing you to access each result individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output keys:  ['x', 'y', 'z']\n",
      "output y shape:  torch.Size([5, 30])\n",
      "output z shape:  torch.Size([5, 30])\n"
     ]
    }
   ],
   "source": [
    "module = dl.Parallel(\n",
    "    dl.Layer(torch.nn.Linear, 10, 30).set_input_map(\"x\").set_output_map(\"y\"),\n",
    "    dl.Layer(torch.nn.Linear, 10, 30).set_input_map(\"x\").set_output_map(\"z\"),\n",
    ")\n",
    "\n",
    "built = module.build()\n",
    "\n",
    "input_data = Data(x=torch.randn(5, 10))\n",
    "\n",
    "output_data = built(input_data)\n",
    "\n",
    "print(\"output keys: \", output_data.keys())\n",
    "print(\"output y shape: \", output_data.y.shape)\n",
    "print(\"output z shape: \", output_data.z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, both linear layers take `x` as input, producing outputs labeled `y` and `z`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify the output mappings directly within `Parallel`'s constructor. In the example below, each module is assigned a key (`y` and `z` for the first and second layer, respectively), and the output mappings are automatically determined based on these keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = dl.Parallel(\n",
    "    y=dl.Layer(torch.nn.Linear, 10, 30).set_input_map(\"x\"),\n",
    "    z=dl.Layer(torch.nn.Linear, 10, 30).set_input_map(\"x\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method streamlines the syntax, but offers less explicit control over output mappings compared to configuring each module individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Mappings with Graph Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deeplay’s graph operations let you input mapping objects directly, simplifying the management of graph data. In graphs, nodes (entities) are connected by edges (relationships), and Deeplay’s mappings makes it easy to work with these inputs. \n",
    "\n",
    "For example, in a graph convolutional neural network (GCN), node features are updated based on information from neighboring nodes. In this example, `x` represents the features of three nodes, while `edge_index` defines the connections between nodes. Deeplay’s GCN layer automatically reads these mappings, processes each node’s features while considering its neighboring nodes, and stores the result back in the mapping for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output keys:  ['x', 'edge_index']\n"
     ]
    }
   ],
   "source": [
    "gcn = dl.components.gcn.GraphConvolutionalNeuralNetwork(\n",
    "    in_features=10, hidden_features=[], out_features=10,\n",
    ")\n",
    "\n",
    "built_gcn = gcn.build()\n",
    "\n",
    "input_data = Data(\n",
    "    x=torch.randn(3, 10),  # Node features for 3 nodes, each with 10 features.\n",
    "    edge_index=torch.tensor(\n",
    "        [\n",
    "            [0, 1, 1, 2], \n",
    "            [1, 0, 2, 1]\n",
    "        ]\n",
    "    ),  # Graph connectivity, indicating edges between nodes.\n",
    ")\n",
    "\n",
    "output_data = built_gcn(input_data)\n",
    "\n",
    "print(\"output keys: \", output_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Mappings to Tensor Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deeplay supports a seamless transition between mapping objects and Tensor objects. The output data structure can be converted to a Tensor object using the `FromDict` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = dl.Sequential(\n",
    "    dl.Layer(torch.nn.Bilinear, 10, 10, 10) \\\n",
    "        .set_input_map(\"x1\", \"x2\").set_output_map(\"y\"),\n",
    "    dl.Layer(LayerNorm, 10) \\\n",
    "        .set_input_map(x=\"y\", batch=\"batch\").set_output_map(\"y\"),\n",
    "    dl.FromDict(\"y\"), \n",
    "    dl.Layer(torch.nn.Linear, 10, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output type:  <class 'torch.Tensor'>\n",
      "output shape:  torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "built = module.build()\n",
    "\n",
    "input_data = Data(\n",
    "    x1=torch.randn(5, 10),\n",
    "    x2=torch.randn(5, 10),\n",
    "    batch=torch.Tensor([0, 0, 0, 1, 1]).long(),\n",
    ")\n",
    "\n",
    "output_data = built(input_data)\n",
    "\n",
    "print(\"output type: \", type(output_data))\n",
    "print(\"output shape: \", output_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
